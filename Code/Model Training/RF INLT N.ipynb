{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Stats\n",
      "Accuracy on Test Set: 0.8657171922685656\n",
      "F1 on Test Set: 0.8718446601941747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       484\n",
      "           1       0.85      0.90      0.87       499\n",
      "\n",
      "    accuracy                           0.87       983\n",
      "   macro avg       0.87      0.87      0.87       983\n",
      "weighted avg       0.87      0.87      0.87       983\n",
      "\n",
      "[[402  82]\n",
      " [ 50 449]]\n",
      "Train Stats\n",
      "Accuracy on Training Set: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       826\n",
      "           1       1.00      1.00      1.00       826\n",
      "\n",
      "    accuracy                           1.00      1652\n",
      "   macro avg       1.00      1.00      1.00      1652\n",
      "weighted avg       1.00      1.00      1.00      1652\n",
      "\n",
      "[[826   0]\n",
      " [  0 826]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import load, dump\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "X_train_val = load('../../BEST SET/X_train_fft.joblib')\n",
    "y_train_val = load('../../BEST SET/y_Train.joblib')\n",
    "X_test = load('../../BEST SET/international_fft.joblib')\n",
    "y_test = load('../../BEST SET/international_labels.joblib') \n",
    "\n",
    "def reshape_data(data):\n",
    "    num_samples = data.shape[0]\n",
    "    num_timesteps = data.shape[1]\n",
    "    num_channels = data.shape[2] \n",
    "    return data.reshape(num_samples, num_timesteps * num_channels) \n",
    "\n",
    "\n",
    "X_train_val = reshape_data(X_train_val)  \n",
    "X_test = reshape_data(X_test)  \n",
    "# Split data into training/validation and test sets\n",
    "\n",
    "base = {'n_estimators': 184, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}\n",
    "subt = {'n_estimators': 292, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}\n",
    "add = {'n_estimators': 280, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}\n",
    "onlyA = {'n_estimators': 85, 'max_depth': 45, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}\n",
    "AandB = {'n_estimators': 227, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}\n",
    "\n",
    "rf = RandomForestClassifier(**base, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Evaluation on test set\n",
    "print(\"Test Stats\")\n",
    "predictions_test = rf.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, predictions_test)\n",
    "print(\"Accuracy on Test Set:\", accuracy_test)\n",
    "f1_test = f1_score(y_test, predictions_test)\n",
    "print(\"F1 on Test Set:\", f1_test)\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print(confusion_matrix(y_test, predictions_test))\n",
    "\n",
    "\n",
    "print(\"Train Stats\")\n",
    "predictions_test_train = rf.predict(X_train_val)\n",
    "accuracy_test = accuracy_score(y_train_val, predictions_test_train)\n",
    "print(\"Accuracy on Training Set:\", accuracy_test)\n",
    "print(classification_report(y_train_val, predictions_test_train))\n",
    "print(confusion_matrix(y_train_val, predictions_test_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_test = load('Windowdata.joblib')\n",
    "window_labels = load('Windowlabels.joblib')\n",
    "\n",
    "window_test = reshape_data(np.array(window_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 1\n",
      "False Positives (FP): 5\n",
      "False Negatives (FN): 0\n"
     ]
    }
   ],
   "source": [
    "def get_triggers(sequence, max_gap=2):\n",
    "    triggers = []\n",
    "    in_trigger = False\n",
    "    gap_count = 0\n",
    "    start = None\n",
    "    \n",
    "    for i, val in enumerate(sequence):\n",
    "        if val == 1:\n",
    "            if not in_trigger:\n",
    "                start = i\n",
    "                in_trigger = True\n",
    "                gap_count = 0\n",
    "            else:\n",
    "                gap_count = 0\n",
    "        elif val == 0 and in_trigger:\n",
    "            gap_count += 1\n",
    "            if gap_count > max_gap:\n",
    "                triggers.append((start, i - gap_count))\n",
    "                in_trigger = False\n",
    "                gap_count = 0\n",
    "    \n",
    "    if in_trigger:\n",
    "        triggers.append((start, len(sequence) - 1))\n",
    "    \n",
    "    return triggers\n",
    "\n",
    "# Function to count true positives (TP), false positives (FP), and false negatives (FN)\n",
    "def count_triggers(predictions, actuals):\n",
    "    TP, FP, FN = 0, 0, 0\n",
    "\n",
    "    pred_triggers = get_triggers(predictions)\n",
    "    actual_triggers = get_triggers(actuals)\n",
    "\n",
    "    # Check for True Positives and False Negatives\n",
    "    for actual in actual_triggers:\n",
    "        actual_detected = False\n",
    "        for pred in pred_triggers:\n",
    "            if (pred[0] <= actual[1] and pred[1] >= actual[0]):\n",
    "                TP += 1\n",
    "                actual_detected = True\n",
    "                break\n",
    "        if not actual_detected:\n",
    "            FN += 1\n",
    "\n",
    "    # Check for False Positives\n",
    "    for pred in pred_triggers:\n",
    "        pred_detected = False\n",
    "        for actual in actual_triggers:\n",
    "            if (pred[0] <= actual[1] and pred[1] >= actual[0]):\n",
    "                pred_detected = True\n",
    "                break\n",
    "        if not pred_detected:\n",
    "            FP += 1\n",
    "\n",
    "    return TP, FP, FN\n",
    "\n",
    "predictions_test = rf.predict(window_test)\n",
    "# Calculate TP, FP, FN\n",
    "TP, FP, FN = count_triggers(predictions_test, window_labels)\n",
    "\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_data(test_set, predictions_test, y_test):\n",
    "    for idx, example in enumerate(test_set):\n",
    "        if predictions_test[idx] == y_test[idx]:\n",
    "            continue\n",
    "        fig, axs = plt.subplots(example.shape[0], sharex=True)\n",
    "        axs[0].set_title(f\"Wrong Classification, Should be {y_test[idx]}\")\n",
    "        axs[0].plot(example[0])\n",
    "        axs[0].set_ylabel(\"HHE\")\n",
    "        axs[1].plot(example[1])\n",
    "        axs[1].set_ylabel(\"HHN\")\n",
    "        axs[2].plot(example[2])\n",
    "        axs[2].set_ylabel(\"HHZ\")\n",
    "\n",
    "        plt.xlabel(\"Time\") \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X_test = load('../BEST SET/raw_X_test.joblib')\n",
    "\n",
    "plot_data(raw_X_test, predictions_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
