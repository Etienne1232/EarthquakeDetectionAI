{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from joblib import load\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = load('../DataDumps/data_fft.joblib')\n",
    "combined_labels = load('../DataDumps/labels.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for validation set:\n",
      " [[68  2  3]\n",
      " [ 8 26  1]\n",
      " [27 12  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.93      0.77        73\n",
      "           1       0.65      0.74      0.69        35\n",
      "           2       0.64      0.15      0.25        46\n",
      "\n",
      "    accuracy                           0.66       154\n",
      "   macro avg       0.65      0.61      0.57       154\n",
      "weighted avg       0.65      0.66      0.60       154\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[91  0  5]\n",
      " [12 34  3]\n",
      " [33 10  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.78        96\n",
      "           1       0.77      0.69      0.73        49\n",
      "           2       0.33      0.09      0.14        47\n",
      "\n",
      "    accuracy                           0.67       192\n",
      "   macro avg       0.59      0.58      0.55       192\n",
      "weighted avg       0.61      0.67      0.61       192\n",
      "\n",
      "Confusion Matrix for validation set:\n",
      " [[72  1  8]\n",
      " [ 8 26  3]\n",
      " [15  8 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82        81\n",
      "           1       0.74      0.70      0.72        37\n",
      "           2       0.54      0.36      0.43        36\n",
      "\n",
      "    accuracy                           0.72       154\n",
      "   macro avg       0.68      0.65      0.66       154\n",
      "weighted avg       0.70      0.72      0.71       154\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[89  0  7]\n",
      " [ 8 36  5]\n",
      " [26  8 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81        96\n",
      "           1       0.82      0.73      0.77        49\n",
      "           2       0.52      0.28      0.36        47\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.69      0.65      0.65       192\n",
      "weighted avg       0.70      0.72      0.69       192\n",
      "\n",
      "Confusion Matrix for validation set:\n",
      " [[69  1  9]\n",
      " [ 5 27  4]\n",
      " [15 13 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        79\n",
      "           1       0.66      0.75      0.70        36\n",
      "           2       0.46      0.28      0.35        39\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.63      0.64      0.62       154\n",
      "weighted avg       0.67      0.69      0.67       154\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[87  0  9]\n",
      " [ 8 34  7]\n",
      " [25  9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.81        96\n",
      "           1       0.79      0.69      0.74        49\n",
      "           2       0.45      0.28      0.34        47\n",
      "\n",
      "    accuracy                           0.70       192\n",
      "   macro avg       0.65      0.63      0.63       192\n",
      "weighted avg       0.67      0.70      0.68       192\n",
      "\n",
      "Confusion Matrix for validation set:\n",
      " [[66  3  5]\n",
      " [11 27  4]\n",
      " [19 10  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78        74\n",
      "           1       0.68      0.64      0.66        42\n",
      "           2       0.47      0.22      0.30        37\n",
      "\n",
      "    accuracy                           0.66       153\n",
      "   macro avg       0.61      0.58      0.58       153\n",
      "weighted avg       0.63      0.66      0.63       153\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[86  1  9]\n",
      " [11 33  5]\n",
      " [27  8 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78        96\n",
      "           1       0.79      0.67      0.73        49\n",
      "           2       0.46      0.26      0.33        47\n",
      "\n",
      "    accuracy                           0.68       192\n",
      "   macro avg       0.65      0.61      0.61       192\n",
      "weighted avg       0.66      0.68      0.66       192\n",
      "\n",
      "Confusion Matrix for validation set:\n",
      " [[65  1 11]\n",
      " [ 7 33  4]\n",
      " [17  7  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78        77\n",
      "           1       0.80      0.75      0.78        44\n",
      "           2       0.35      0.25      0.29        32\n",
      "\n",
      "    accuracy                           0.69       153\n",
      "   macro avg       0.63      0.61      0.62       153\n",
      "weighted avg       0.67      0.69      0.68       153\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[85  1 10]\n",
      " [ 9 35  5]\n",
      " [29  7 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78        96\n",
      "           1       0.81      0.71      0.76        49\n",
      "           2       0.42      0.23      0.30        47\n",
      "\n",
      "    accuracy                           0.68       192\n",
      "   macro avg       0.64      0.61      0.61       192\n",
      "weighted avg       0.66      0.68      0.66       192\n",
      "\n",
      "Average Accuracy on Test Set: 0.6906249999999999\n",
      "Best hyperparameters for each fold:\n",
      "Fold 1: {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "Fold 2: {'n_neighbors': 8, 'weights': 'distance'}\n",
      "Fold 3: {'n_neighbors': 6, 'weights': 'distance'}\n",
      "Fold 4: {'n_neighbors': 6, 'weights': 'distance'}\n",
      "Fold 5: {'n_neighbors': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from joblib import load\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load data\n",
    "combined_data = load('../DataDumps/data_fft.joblib')\n",
    "combined_labels = load('../DataDumps/labels.joblib')\n",
    "\n",
    "# Define a function to reshape the data\n",
    "def reshape_data(data):\n",
    "    num_samples = data.shape[0]\n",
    "    num_timesteps = data.shape[1]\n",
    "    num_channels = data.shape[2]\n",
    "    return data.reshape(num_samples, num_timesteps * num_channels) \n",
    "\n",
    "combined_data1 = reshape_data(combined_data)  \n",
    "\n",
    "# Split data into training/validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(combined_data1, combined_labels, test_size=0.2, stratify=combined_labels, random_state=0)\n",
    "\n",
    "# Define K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 10)),  # Try odd numbers of neighbors\n",
    "    'weights': ['uniform', 'distance'],   # Weighting schemes\n",
    "} \n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize variables to store best hyperparameters and accuracies\n",
    "best_hyperparams = []\n",
    "best_accuracies = []\n",
    "\n",
    "# Perform hyperparameter tuning and K-Fold cross-validation\n",
    "for train_index, val_index in kf.split(X_train_val):\n",
    "    X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "    y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=kf)\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best KNN model from GridSearchCV\n",
    "    best_knn = grid_search.best_estimator_\n",
    "    \n",
    "    # Store best hyperparameters\n",
    "    best_hyperparams.append(grid_search.best_params_)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    predictions_val = best_knn.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy on validation set\n",
    "    accuracy_val = accuracy_score(y_val, predictions_val)\n",
    "    \n",
    "    # Print confusion matrix and classification report for each fold\n",
    "    cm = confusion_matrix(y_val, predictions_val)\n",
    "    print(\"Confusion Matrix for validation set:\\n\", cm)\n",
    "    print(classification_report(y_val, predictions_val))\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    predictions_test = best_knn.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy on test set\n",
    "    accuracy_test = accuracy_score(y_test, predictions_test)\n",
    "    best_accuracies.append(accuracy_test)\n",
    "    \n",
    "    # Print confusion matrix and classification report for test set\n",
    "    cm_test = confusion_matrix(y_test, predictions_test)\n",
    "    print(\"Confusion Matrix for test set:\\n\", cm_test)\n",
    "    print(classification_report(y_test, predictions_test))\n",
    "\n",
    "# Print average accuracy across all folds for test set\n",
    "print(\"Average Accuracy on Test Set:\", np.mean(best_accuracies))\n",
    "\n",
    "# Print the best hyperparameters found during each fold\n",
    "print(\"Best hyperparameters for each fold:\")\n",
    "for i, params in enumerate(best_hyperparams):\n",
    "    print(\"Fold {}: {}\".format(i+1, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for validation set:\n",
      " [[64  9]\n",
      " [33 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.75        73\n",
      "           1       0.84      0.59      0.70        81\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.75      0.73      0.72       154\n",
      "weighted avg       0.76      0.73      0.72       154\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[85 11]\n",
      " [32 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80        96\n",
      "           1       0.85      0.67      0.75        96\n",
      "\n",
      "    accuracy                           0.78       192\n",
      "   macro avg       0.79      0.78      0.77       192\n",
      "weighted avg       0.79      0.78      0.77       192\n",
      "\n",
      "Confusion Matrix for validation set:\n",
      " [[70 11]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80        81\n",
      "           1       0.81      0.66      0.73        73\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.78      0.76      0.76       154\n",
      "weighted avg       0.77      0.77      0.76       154\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[85 11]\n",
      " [28 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81        96\n",
      "           1       0.86      0.71      0.78        96\n",
      "\n",
      "    accuracy                           0.80       192\n",
      "   macro avg       0.81      0.80      0.80       192\n",
      "weighted avg       0.81      0.80      0.80       192\n",
      "\n",
      "Confusion Matrix for validation set:\n",
      " [[69 10]\n",
      " [23 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81        79\n",
      "           1       0.84      0.69      0.76        75\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.79      0.78      0.78       154\n",
      "weighted avg       0.79      0.79      0.78       154\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[87  9]\n",
      " [30 66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82        96\n",
      "           1       0.88      0.69      0.77        96\n",
      "\n",
      "    accuracy                           0.80       192\n",
      "   macro avg       0.81      0.80      0.79       192\n",
      "weighted avg       0.81      0.80      0.79       192\n",
      "\n",
      "Confusion Matrix for validation set:\n",
      " [[67  7]\n",
      " [20 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83        74\n",
      "           1       0.89      0.75      0.81        79\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.83      0.83      0.82       153\n",
      "weighted avg       0.83      0.82      0.82       153\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[87  9]\n",
      " [31 65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.81        96\n",
      "           1       0.88      0.68      0.76        96\n",
      "\n",
      "    accuracy                           0.79       192\n",
      "   macro avg       0.81      0.79      0.79       192\n",
      "weighted avg       0.81      0.79      0.79       192\n",
      "\n",
      "Confusion Matrix for validation set:\n",
      " [[67 10]\n",
      " [20 56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82        77\n",
      "           1       0.85      0.74      0.79        76\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.81      0.80      0.80       153\n",
      "weighted avg       0.81      0.80      0.80       153\n",
      "\n",
      "Confusion Matrix for test set:\n",
      " [[85 11]\n",
      " [28 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81        96\n",
      "           1       0.86      0.71      0.78        96\n",
      "\n",
      "    accuracy                           0.80       192\n",
      "   macro avg       0.81      0.80      0.80       192\n",
      "weighted avg       0.81      0.80      0.80       192\n",
      "\n",
      "Average Accuracy on Test Set: 0.7916666666666666\n",
      "Best hyperparameters for each fold:\n",
      "Fold 1: {'n_neighbors': 4, 'weights': 'distance'}\n",
      "Fold 2: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Fold 3: {'n_neighbors': 6, 'weights': 'distance'}\n",
      "Fold 4: {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "Fold 5: {'n_neighbors': 6, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from joblib import load\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load data\n",
    "combined_data = load('../DataDumps/data_fft.joblib')\n",
    "combined_labels = load('../DataDumps/labels.joblib')\n",
    "\n",
    "combined_labels[combined_labels == 2] = 1\n",
    "\n",
    "\n",
    "# Define a function to reshape the data\n",
    "def reshape_data(data):\n",
    "    num_samples = data.shape[0]\n",
    "    num_timesteps = data.shape[1]\n",
    "    num_channels = data.shape[2]\n",
    "    return data.reshape(num_samples, num_timesteps * num_channels) \n",
    "\n",
    "combined_data1 = reshape_data(combined_data)  \n",
    "\n",
    "# Split data into training/validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(combined_data1, combined_labels, test_size=0.2, stratify=combined_labels, random_state=0)\n",
    "\n",
    "# Define K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 10)),  # Try odd numbers of neighbors\n",
    "    'weights': ['uniform', 'distance'],   # Weighting schemes\n",
    "} \n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize variables to store best hyperparameters and accuracies\n",
    "best_hyperparams = []\n",
    "best_accuracies = []\n",
    "\n",
    "# Perform hyperparameter tuning and K-Fold cross-validation\n",
    "for train_index, val_index in kf.split(X_train_val):\n",
    "    X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "    y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=kf)\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best KNN model from GridSearchCV\n",
    "    best_knn = grid_search.best_estimator_\n",
    "    \n",
    "    # Store best hyperparameters\n",
    "    best_hyperparams.append(grid_search.best_params_)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    predictions_val = best_knn.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy on validation set\n",
    "    accuracy_val = accuracy_score(y_val, predictions_val)\n",
    "    \n",
    "    # Print confusion matrix and classification report for each fold\n",
    "    cm = confusion_matrix(y_val, predictions_val)\n",
    "    print(\"Confusion Matrix for validation set:\\n\", cm)\n",
    "    print(classification_report(y_val, predictions_val))\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    predictions_test = best_knn.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy on test set\n",
    "    accuracy_test = accuracy_score(y_test, predictions_test)\n",
    "    best_accuracies.append(accuracy_test)\n",
    "    \n",
    "    # Print confusion matrix and classification report for test set\n",
    "    cm_test = confusion_matrix(y_test, predictions_test)\n",
    "    print(\"Confusion Matrix for test set:\\n\", cm_test)\n",
    "    print(classification_report(y_test, predictions_test))\n",
    "\n",
    "# Print average accuracy across all folds for test set\n",
    "print(\"Average Accuracy on Test Set:\", np.mean(best_accuracies))\n",
    "\n",
    "# Print the best hyperparameters found during each fold\n",
    "print(\"Best hyperparameters for each fold:\")\n",
    "for i, params in enumerate(best_hyperparams):\n",
    "    print(\"Fold {}: {}\".format(i+1, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
