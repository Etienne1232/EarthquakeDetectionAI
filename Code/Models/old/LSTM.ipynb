{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from joblib import load, dump\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = load('../../DataDumps/all_data_fft - balanced YesandNo.joblib')\n",
    "combined_labels = load('../../DataDumps/2class_labels.joblib')\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(combined_data, combined_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_units=100, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 11ms/step - loss: 0.6335 - accuracy: 0.6654\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7651\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.6192 - accuracy: 0.6820\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7259\n",
      "42/42 [==============================] - 2s 8ms/step - loss: 0.6027 - accuracy: 0.6918\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7500\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.6067 - accuracy: 0.7046\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7440\n",
      "42/42 [==============================] - 2s 7ms/step - loss: 0.5812 - accuracy: 0.7101\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7462\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)  \n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X_train_val, y_train_val):\n",
    "    X_tr, X_val = X_train_val[train_index], X_train_val[test_index]\n",
    "    y_tr, y_val = y_train_val[train_index], y_train_val[test_index]\n",
    "    model = create_model()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    scores.append(model.evaluate(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8330\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8131\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8282\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8288\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.8240\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8312\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8324\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8294\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8312\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8210\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8354\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8348\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8306\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8330\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3258 - accuracy: 0.8312\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8348\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8149\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8294\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8403\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8222\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8240\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8234\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8324\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.8379\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8348\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8348\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8282\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8342\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8186\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3248 - accuracy: 0.8354\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8306\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8318\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8264\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8336\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8324\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.8366\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8270\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8318\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8318\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3216 - accuracy: 0.8391\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8391\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8415\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8204\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3194 - accuracy: 0.8354\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3253 - accuracy: 0.8391\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8348\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3252 - accuracy: 0.8487\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8294\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8505\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8397\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.8397\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8294\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3223 - accuracy: 0.8282\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8391\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.8336\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8409\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8439\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.8318\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.8294\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.8336\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8373\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8366\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8379\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3216 - accuracy: 0.8336\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8246\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8294\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8366\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8324\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3091 - accuracy: 0.8403\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8391\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3227 - accuracy: 0.8391\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8318\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3207 - accuracy: 0.8336\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.8415\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8366\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8312\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8360\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3145 - accuracy: 0.8421\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8397\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8505\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8475\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.8469\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8433\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8348\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3196 - accuracy: 0.8391\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8445\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.8505\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.8535\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8385\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3134 - accuracy: 0.8415\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8409\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8415\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.8457\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3153 - accuracy: 0.8475\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3059 - accuracy: 0.8366\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8403\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3147 - accuracy: 0.8409\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3084 - accuracy: 0.8541\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8366\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8445\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3048 - accuracy: 0.8445\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3165 - accuracy: 0.8324\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3047 - accuracy: 0.8451\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8445\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8379\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3065 - accuracy: 0.8385\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8421\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3196 - accuracy: 0.8282\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8379\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3161 - accuracy: 0.8415\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8397\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8499\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8463\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8366\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8481\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3118 - accuracy: 0.8487\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.8421\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.8427\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8457\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.8397\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.8535\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8427\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3107 - accuracy: 0.8469\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3125 - accuracy: 0.8421\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3139 - accuracy: 0.8409\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3050 - accuracy: 0.8366\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8318\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.8505\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8547\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3020 - accuracy: 0.8457\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3063 - accuracy: 0.8421\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8493\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3102 - accuracy: 0.8445\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8415\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3094 - accuracy: 0.8505\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3084 - accuracy: 0.8541\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3064 - accuracy: 0.8475\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3064 - accuracy: 0.8475\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.8433\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3025 - accuracy: 0.8457\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3055 - accuracy: 0.8529\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2943 - accuracy: 0.8547\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.8475\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.8553\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.8427\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3099 - accuracy: 0.8487\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8433\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2937 - accuracy: 0.8463\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.8433\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2996 - accuracy: 0.8451\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step\n",
      "Test Accuracy: 0.7807228915662651\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0) \n",
    "\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
